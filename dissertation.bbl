% Generated by IEEEtran.bst, version: 1.12 (2007/01/11)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{cao2018}
J.~Cao, W.~Li, C.~Ma, and Z.~Tao, ``Optimizing multi-sensor deployment via ensemble pruning for wearable activity recognition,'' \emph{Information Fusion}, vol.~41, pp. 68--79, 2018.

\bibitem{breiman1996}
L.~Breiman, ``Bagging predictors,'' \emph{Machine learning}, vol.~24, no.~2, pp. 123--140, 1996.

\bibitem{martinez2004}
G.~Mart{\i}nez-Munoz and A.~Su{\'a}rez, ``Aggregation ordering in bagging,'' in \emph{Proc. of the IASTED International Conference on Artificial Intelligence and Applications}.\hskip 1em plus 0.5em minus 0.4em\relax Citeseer, 2004, pp. 258--263.

\bibitem{martinez2009}
G.~Mart{\'\i}nez-Mu{\~n}oz, D.~Hern{\'a}ndez-Lobato, and A.~Su{\'a}rez, ``An analysis of ensemble pruning techniques based on ordered aggregation,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol.~31, no.~2, pp. 245--259, 2008.

\bibitem{guo2013}
L.~Guo and S.~Boukir, ``Margin-based ordered aggregation for ensemble pruning,'' \emph{Pattern Recognition Letters}, vol.~34, no.~6, pp. 603--609, 2013.

\bibitem{guo2018}
H.~Guo, H.~Liu, R.~Li, C.~Wu, Y.~Guo, and M.~Xu, ``Margin \& diversity based ordering ensemble pruning,'' \emph{Neurocomputing}, vol. 275, pp. 237--246, 2018.

\bibitem{lu2010}
Z.~Lu, X.~Wu, X.~Zhu, and J.~Bongard, ``Ensemble pruning via individual contribution ordering,'' in \emph{Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining}, 2010, pp. 871--880.

\bibitem{zhou2002}
Z.-H. Zhou, J.~Wu, and W.~Tang, ``Ensembling neural networks: many could be better than all,'' \emph{Artificial intelligence}, vol. 137, no. 1-2, pp. 239--263, 2002.

\bibitem{diao2013}
R.~Diao, F.~Chao, T.~Peng, N.~Snooke, and Q.~Shen, ``Feature selection inspired classifier ensemble reduction,'' \emph{IEEE transactions on cybernetics}, vol.~44, no.~8, pp. 1259--1268, 2013.

\bibitem{margineantu1997}
D.~D. Margineantu and T.~G. Dietterich, ``Pruning adaptive boosting,'' in \emph{ICML}, vol.~97.\hskip 1em plus 0.5em minus 0.4em\relax Citeseer, 1997, pp. 211--218.

\bibitem{sakar2012}
C.~O. Sakar, O.~Kursun, and F.~Gurgen, ``A feature selection method based on kernel canonical correlation analysis and the minimum redundancy--maximum relevance filter method,'' \emph{Expert Systems with Applications}, vol.~39, no.~3, pp. 3432--3437, 2012.

\bibitem{unler2011}
A.~Unler, A.~Murat, and R.~B. Chinnam, ``mr2pso: A maximum relevance minimum redundancy feature selection method based on swarm intelligence for support vector machine classification,'' \emph{Information Sciences}, vol. 181, no.~20, pp. 4625--4641, 2011.

\bibitem{breiman2001}
L.~Breiman, ``Random forests,'' \emph{Machine learning}, vol.~45, no.~1, pp. 5--32, 2001.

\bibitem{freund1997}
Y.~Freund and R.~E. Schapire, ``A decision-theoretic generalization of on-line learning and an application to boosting,'' \emph{Journal of computer and system sciences}, vol.~55, no.~1, pp. 119--139, 1997.

\bibitem{quinlan2014}
J.~Quinlan, \emph{C4. 5: programs for machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax Elsevier, 2014.

\bibitem{friedman1937}
M.~Friedman, ``The use of ranks to avoid the assumption of normality implicit in the analysis of variance,'' \emph{Journal of the american statistical association}, vol.~32, no. 200, pp. 675--701, 1937.

\bibitem{wilcoxon1992}
F.~Wilcoxon, ``Individual comparisons by ranking methods,'' in \emph{Breakthroughs in statistics}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 1992, pp. 196--202.

\bibitem{garcia2008}
S.~Garcia and F.~Herrera, ``An extension on statistical comparisons of classifiers over multiple data sets for all pairwise comparisons,'' \emph{Journal of machine learning research}, vol.~9, no. Dec, pp. 2677--2694, 2008.

\bibitem{demvsar2006}
J.~Dem{\v{s}}ar, ``Statistical comparisons of classifiers over multiple data sets,'' \emph{Journal of Machine learning research}, vol.~7, no. Jan, pp. 1--30, 2006.

\bibitem{onan2016}
A.~Onan, S.~Koruko{\u{g}}lu, and H.~Bulut, ``A multiobjective weighted voting ensemble classifier based on differential evolution algorithm for text sentiment classification,'' \emph{Expert Systems with Applications}, vol.~62, pp. 1--16, 2016.

\bibitem{wolpert2002}
D.~H. Wolpert, ``The supervised learning no-free-lunch theorems,'' in \emph{Soft computing and industry}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2002, pp. 25--42.

\bibitem{tomek1976}
I.~Tomek, ``An experiment with the edited nearest-neighbor rule,'' \emph{IEEE Transactions on systems, Man, and Cybernetics}, vol.~6, no.~6, pp. 448--452, 1976.

\bibitem{garcia2011}
S.~Garcia, J.~Derrac, J.~R. Cano, and F.~Herrera, ``Prototype selection for nearest neighbor classification: Taxonomy and empirical study,'' \emph{IEEE Transactions on Pattern Analysis \& Machine Intelligence}, no.~3, pp. 417--435, 2011.

\bibitem{liu2017}
C.~Liu, W.~Wang, M.~Wang, F.~Lv, and M.~Konan, ``An efficient instance selection algorithm to reconstruct training set for support vector machine,'' \emph{Knowledge-Based Systems}, vol. 116, pp. 58--73, 2017.

\bibitem{chen2013}
J.~Chen, C.~Zhang, X.~Xue, and C.-L. Liu, ``Fast instance selection for speeding up support vector machines,'' \emph{Knowledge-Based Systems}, vol.~45, pp. 1--7, 2013.

\bibitem{rosales2017}
A.~Rosales-P{\'e}rez, S.~Garc{\'\i}a, J.~A. Gonzalez, C.~A.~C. Coello, and F.~Herrera, ``An evolutionary multiobjective model and instance selection for support vector machines with pareto-based ensembles,'' \emph{IEEE Transactions on Evolutionary Computation}, vol.~21, no.~6, pp. 863--877, 2017.

\bibitem{fletcher2020}
S.~Fletcher, B.~Verma, and M.~Zhang, ``A non-specialized ensemble classifier using multi-objective optimization,'' \emph{Neurocomputing}, 2020.

\bibitem{sikora2015}
R.~Sikora \emph{et~al.}, ``A modified stacking ensemble machine learning algorithm using genetic algorithms,'' in \emph{Handbook of Research on Organizational Transformations through Big Data Analytics}, 2015, pp. 43--53.

\bibitem{dai2015}
Q.~Dai, T.~Zhang, and N.~Liu, ``A new reverse reduce-error ensemble pruning algorithm,'' \emph{Applied Soft Computing}, vol.~28, pp. 237--249, 2015.

\bibitem{li2014}
L.~Li, Q.~Hu, X.~Wu, and D.~Yu, ``Exploration of classification confidence in ensemble learning,'' \emph{Pattern recognition}, vol.~47, no.~9, pp. 3120--3131, 2014.

\end{thebibliography}
