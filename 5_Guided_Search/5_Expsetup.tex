%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   Results
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental Results}
\label{ch5_expsetup}
The experiments are dedicated to achieving objective 2, to increase the efficiency of MCS, and to go beyond what can be achieved from ensemble pruning methods. The two main questions to be answered are:
\begin{itemize}[nosep]
\setlength{\itemindent}{-.5in}
    \item $\pmb{Q_3}$. What is the effect of combining multiple pruning metrics together? 
    \item $\pmb{Q_4}$. What is the effect of downsizing data and downsizing the number of classifiers simultaneously? 
\end{itemize}

\subsection{Setup of Experiments}
During setup and validation, all datasets are preprocessed by unifying the scale of the features via normalization. For each dataset, 20 repetitions with 5 fold cross-validation procedure are considered. Thus, a total of 100 runs per dataset. The accuracy metric is calculated by the majority voting of all ensemble members. In addition, MDEP depends on an internal parameter $\alpha$; three values for MDEP with different $\alpha \in \{0.1, 0.5,0.9\}$ are considered, and the best-optimized alpha according to the in train-validation is used to report the test for each dataset separately.

A total number of 25 datasets captured from OpenML\footnote{ Machine Learning Repository: https://www.openml.org} and KEEL \footnote{KEEL Repository: http://www.keel.es/} are used in this work in order to provide experimentation. The characteristics of data can be found in Table \ref{ch5_data}, where \#S, \#F, \#C, and R represent the number of samples, the number of features, the number of classes, and the ratio between the smallest and the largest class for each dataset respectively. 


\vspace*{.3cm}
\begin{table}[!ht]
\centering\scriptsize
\caption{Characteristics of the selected datasets for experimentation, \textit{sorted by samples and classes}.}
 \label{ch5_data}
\resizebox{\textwidth}{!}{\begin{tabular}{l|cccc||l|cccc}
  \hline
\multicolumn{1}{c|}{DataSet} & \#S & \#F &  \#C & R  &DataSet & \#S & \#F &  \#C & R \\ 
  \hline
  Heart-statlog & 270 & 13 & 2 & 0.8 & Waveform & \numprint{4999} & 21 & 3 &  0.972 \\
   Heart-c & 303 & 13 & 2 & 0.836 & Cleveland & 297 & 13 &  5 & 0.081 \\ 
Ionosphere & 351 & 33 & 2 & 0.56 & Dermatology & 358 & 34 & 6 & 0.18 \\ 
  Sa-heart & 462 & 9 & 2 & 0.529 & Satimage & \numprint{6435} & 36 & 6 &  0.408 \\ 
  Wdbc & 569 & 30 & 2 &  0.594 & Segment & \numprint{2310} & 18 & 7 &  1.0 \\ 
  Breast-w & 699 & 9 & 2 &  0.526 & Mfeat-fourier & \numprint{2000} & 76 & 10  & 1.0 \\  
  Australian & 690 & 14 &  2 & 0.802 &  Mfeat-karh & \numprint{2000} & 64 & 10  & 1.0\\
  Blood-transfusion & 748 & 4 & 2 & 0.312  &Mfeat-zernike & \numprint{2000} & 47 & 10 & 1.0 \\   
  Mammographic & 830 & 5 & 2 & 0.944  & Led24 & \numprint{3200} & 24 & 10 & 0.878 \\  
 Diabetic Retinopathy & \numprint{1151} & 19 & 2 & 0.884  & Optdigits & \numprint{5620} & 62 & 10  & 0.969 \\
 Abalone & \numprint{4177} & 8 & 2 & 0.464   & Penbased & \numprint{10992} & 16 & 10  & 0.922 \\
 Ringnorm & \numprint{7400} & 20 & 2 & 0.981   & Texture & \numprint{5500} & 40 & 11 & 1.0 \\ 
 Twonorm &\numprint{7400} & 20 & 2 & 0.998 &  & & & & \\  
\hline
\end{tabular}
}
\label{dataset}
\end{table}





